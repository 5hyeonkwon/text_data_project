{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konlpy를 이용한 TDM 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>contents</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200501</td>\n",
       "      <td>앵커 오는   일부터 전 국민에게 긴급 재난지원금을 나눠준다는데 이게 그냥 가만히...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200501</td>\n",
       "      <td>미국 유명 래퍼 트래비스 스콧이 지난   일 연 콘서트에     만 명이 몰렸다 ...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200501</td>\n",
       "      <td>근로장려세제처럼 환급형 세액공제로 해야 면세자는 기부해도    못 돌려받아저소득층...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200501</td>\n",
       "      <td>코로나   항체검사 시행 시 숨겨진 감염자 확인 가능 국내도 코로나   감염 모른...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200501</td>\n",
       "      <td>머니투데이</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20200501</td>\n",
       "      <td>머니투데이 세종</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20200501</td>\n",
       "      <td>사례 씨는 직장 근처에 전셋집을 구해 계약서를 썼다 그러나 집주인의 사정으로 계약...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20200501</td>\n",
       "      <td>한경 지자체 전수 조사광역단체  곳 중복 지급긴급재난지원금 코로나지원금 지급을 위...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20200501</td>\n",
       "      <td>뉴스데스크 앵커 항공 여행 업계가 코로나  로 직격탄을 맞으면서 면세점들도 덩달아...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20200501</td>\n",
       "      <td>국내 주요 면세점들은 코로나   사태로 관광객이 줄면서 재고가 늘어나자 인천 영종...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date                                           contents  section\n",
       "0  20200501   앵커 오는   일부터 전 국민에게 긴급 재난지원금을 나눠준다는데 이게 그냥 가만히...      101\n",
       "1  20200501   미국 유명 래퍼 트래비스 스콧이 지난   일 연 콘서트에     만 명이 몰렸다 ...      101\n",
       "2  20200501   근로장려세제처럼 환급형 세액공제로 해야 면세자는 기부해도    못 돌려받아저소득층...      101\n",
       "3  20200501   코로나   항체검사 시행 시 숨겨진 감염자 확인 가능 국내도 코로나   감염 모른...      101\n",
       "4  20200501                                             머니투데이       101\n",
       "5  20200501                                          머니투데이 세종       101\n",
       "6  20200501   사례 씨는 직장 근처에 전셋집을 구해 계약서를 썼다 그러나 집주인의 사정으로 계약...      101\n",
       "7  20200501   한경 지자체 전수 조사광역단체  곳 중복 지급긴급재난지원금 코로나지원금 지급을 위...      101\n",
       "8  20200501   뉴스데스크 앵커 항공 여행 업계가 코로나  로 직격탄을 맞으면서 면세점들도 덩달아...      101\n",
       "9  20200501   국내 주요 면세점들은 코로나   사태로 관광객이 줄면서 재고가 늘어나자 인천 영종...      101"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('news_data.csv', encoding = 'cp949')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(df.groupby(['date', 'section'])['contents'].apply(lambda x : ','.join(x))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>section</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200123</td>\n",
       "      <td>101</td>\n",
       "      <td>일자리 대전환시대 일자리 못 만드는 중후장대산업차산업 전동화 자동화시대 전환  명...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200123</td>\n",
       "      <td>102</td>\n",
       "      <td>윤석열 검찰총장 왼쪽 과 이성윤 서울중앙지검장 연합뉴스 뉴스  이성윤    사법연...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200123</td>\n",
       "      <td>103</td>\n",
       "      <td>김지은의 삶도 인터뷰    배우 정영주안해본 알바 없고 성추행범 퇴치도 여러 번 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200123</td>\n",
       "      <td>104</td>\n",
       "      <td>중국 연구진 유전자 분석 결과 국제학술지 게재 식재료로 뱀 파는 우한 해산물도매시...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200123</td>\n",
       "      <td>105</td>\n",
       "      <td>무료체험    만명중    만명 자동 유료전환 전환율    달해유튜브 슬그머니 유...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  section                                           contents\n",
       "0  20200123      101   일자리 대전환시대 일자리 못 만드는 중후장대산업차산업 전동화 자동화시대 전환  명...\n",
       "1  20200123      102   윤석열 검찰총장 왼쪽 과 이성윤 서울중앙지검장 연합뉴스 뉴스  이성윤    사법연...\n",
       "2  20200123      103   김지은의 삶도 인터뷰    배우 정영주안해본 알바 없고 성추행범 퇴치도 여러 번 ...\n",
       "3  20200123      104   중국 연구진 유전자 분석 결과 국제학술지 게재 식재료로 뱀 파는 우한 해산물도매시...\n",
       "4  20200123      105   무료체험    만명중    만명 자동 유료전환 전환율    달해유튜브 슬그머니 유..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['이다','하다','돼다','되다']\n",
    "with open(\"stopwords.txt\", \"r\") as f :\n",
    "    for line in f.readlines() :\n",
    "        line = line.strip('\\n')\n",
    "        stop_words.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [03:32<00:00,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "data_okt = []\n",
    "\n",
    "texts = list(data.contents)\n",
    "for i in tqdm(range(len(texts))) :\n",
    "    token = []\n",
    "    try :\n",
    "        token = okt.nouns(texts[i])\n",
    "        token = [word for word in token if not word in stop_words]\n",
    "        data_okt.append(token)\n",
    "    except :\n",
    "        data_okt.append(texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data_okt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 총 갯수 : 29010\n",
      "2번 이상으로 안 나온 단어 수 2: 12957\n",
      "단어에서 2번이상으로 안나온 단어들 비율: 44.663908996897625\n"
     ]
    }
   ],
   "source": [
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) \n",
    "rare_cnt = 0 \n",
    "\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "\n",
    "print('단어 총 갯수 :',total_cnt)\n",
    "print('2번 이상으로 안 나온 단어 수 %s: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어에서 2번이상으로 안나온 단어들 비율:\", (rare_cnt / total_cnt)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_okt_join = [','.join(word) for word in data_okt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=total_cnt-rare_cnt)\n",
    "tdm = cv.fit_transform(data_okt_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = pd.DataFrame({\n",
    "    '단어' : cv.get_feature_names(),\n",
    "    '빈도' : tdm.sum(axis = 0).flat\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16053, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tdm[:400, :]\n",
    "X_test = tdm[400:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 16053)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=15, random_state=555)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=15, random_state=555)\n",
    "svd.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(svd.explained_variance_, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=6, random_state=555)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=6, random_state=555)\n",
    "svd.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = pd.DataFrame(svd.components_.T)\n",
    "loading['word'] = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15805</th>\n",
       "      <td>환자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>병원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>우한</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>울산</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8177</th>\n",
       "      <td>신종</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>만원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11890</th>\n",
       "      <td>정부</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4694</th>\n",
       "      <td>미국</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15136</th>\n",
       "      <td>한국</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13774</th>\n",
       "      <td>코로나</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16053 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word\n",
       "15805   환자\n",
       "5560    병원\n",
       "9872    우한\n",
       "9910    울산\n",
       "8177    신종\n",
       "...    ...\n",
       "4041    만원\n",
       "11890   정부\n",
       "4694    미국\n",
       "15136   한국\n",
       "13774  코로나\n",
       "\n",
       "[16053 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loading.sort_values(2, ascending=False).loc[:,['word']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어 의미 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 16053)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb = svd.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16053, 6)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5373"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = words.index('번방')\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00425214,  0.00390684,  0.00592557, -0.01431209, -0.01345775,\n",
       "        0.00031178])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics.pairwise import cosine_similarity\n",
    "sim = cosine_similarity(word_emb, word_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스티커\n",
      "수법\n",
      "퇴장\n",
      "음란물\n",
      "양은\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rank = np.argsort(sim[i])\n",
    "for j in rank[-6:-1]:\n",
    "    print(words[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_101 = X_train[[x for x in range(X_train.shape[0]) if x % 5 == 0]]\n",
    "X_train_102 = X_train[[x+1 for x in range(X_train.shape[0]) if x % 5 == 0]]\n",
    "X_train_103 = X_train[[x+2 for x in range(X_train.shape[0]) if x % 5 == 0]]\n",
    "X_train_104 = X_train[[x+3 for x in range(X_train.shape[0]) if x % 5 == 0]]\n",
    "X_train_105 = X_train[[x+4 for x in range(X_train.shape[0]) if x % 5 == 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5) :\n",
    "    globals()['X_test_{}'.format(i+1)] = X_test[[x+i for x in range(X_test.shape[0]) if x % 5 == 0 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import Sparse2Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for X_train_ in [X_train_101, X_train_102, X_train_103, X_train_104,X_train_105] :\n",
    "    globals()['corpus_{}'.format(i)]= Sparse2Corpus(X_train_.T) \n",
    "    id2word = dict(enumerate(cv.get_feature_names()))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5) :\n",
    "    globals()['corpus_test_{}'.format(i+1)] = Sparse2Corpus(globals()['X_test_{}'.format(i+1)].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경제 분야 데이터\n",
      "0 LdaModel(num_terms=16053, num_topics=3, decay=0.5, chunksize=2000) 혼란도:  608.0651015177192 응집도:  -0.6008614374832613\n",
      "0 LdaModel(num_terms=16053, num_topics=4, decay=0.5, chunksize=2000) 혼란도:  702.3730216247113 응집도:  -1.54486699808366\n",
      "0 LdaModel(num_terms=16053, num_topics=5, decay=0.5, chunksize=2000) 혼란도:  833.07070432503 응집도:  -0.7327055402155238\n",
      "0\n",
      "******************************\n",
      "('마스크', 0.0041308845)\n",
      "('코로나', 0.0039166645)\n",
      "('미국', 0.0034998537)\n",
      "('중국', 0.0034626767)\n",
      "('정부', 0.0033105419)\n",
      "('억원', 0.0029899974)\n",
      "('갤럭시', 0.002973986)\n",
      "('사진', 0.002956167)\n",
      "\n",
      "******************************\n",
      "1\n",
      "******************************\n",
      "('코로나', 0.007200254)\n",
      "('지역', 0.0045592366)\n",
      "('만원', 0.0045510726)\n",
      "('정부', 0.0043106335)\n",
      "('서울', 0.004230998)\n",
      "('마스크', 0.004118922)\n",
      "('회장', 0.004027574)\n",
      "('아파트', 0.0038631342)\n",
      "\n",
      "******************************\n",
      "2\n",
      "******************************\n",
      "('코로나', 0.009424512)\n",
      "('마스크', 0.007797258)\n",
      "('정부', 0.00603665)\n",
      "('만원', 0.005715039)\n",
      "('한국', 0.00500752)\n",
      "('서울', 0.0049189217)\n",
      "('억원', 0.004819665)\n",
      "('주택', 0.0044656545)\n",
      "\n",
      "******************************\n",
      "사회 분야 데이터\n",
      "1 LdaModel(num_terms=16053, num_topics=3, decay=0.5, chunksize=2000) 혼란도:  851.9454605959295 응집도:  -0.7292448752513448\n",
      "1 LdaModel(num_terms=16053, num_topics=4, decay=0.5, chunksize=2000) 혼란도:  1045.813655591882 응집도:  -0.6718279219598585\n",
      "1 LdaModel(num_terms=16053, num_topics=5, decay=0.5, chunksize=2000) 혼란도:  1258.2559094972903 응집도:  -0.8484567720853015\n",
      "0\n",
      "******************************\n",
      "('환자', 0.017475288)\n",
      "('병원', 0.009069025)\n",
      "('코로나', 0.008682705)\n",
      "('확진', 0.008543578)\n",
      "('격리', 0.007848409)\n",
      "('신종', 0.007825535)\n",
      "('진자', 0.0073805996)\n",
      "('감염', 0.007145966)\n",
      "\n",
      "******************************\n",
      "1\n",
      "******************************\n",
      "('코로나', 0.015286142)\n",
      "('병원', 0.008223536)\n",
      "('진자', 0.008103507)\n",
      "('환자', 0.007915273)\n",
      "('대구', 0.0066438974)\n",
      "('검사', 0.0060994923)\n",
      "('신천지', 0.005484827)\n",
      "('마스크', 0.005482194)\n",
      "\n",
      "******************************\n",
      "2\n",
      "******************************\n",
      "('코로나', 0.009441092)\n",
      "('마스크', 0.0063522416)\n",
      "('경찰', 0.0053217513)\n",
      "('서울', 0.0048884293)\n",
      "('지난', 0.0044332435)\n",
      "('격리', 0.003962775)\n",
      "('확인', 0.003915849)\n",
      "('환자', 0.0038826899)\n",
      "\n",
      "******************************\n",
      "생활/문화 분야 데이터\n",
      "2 LdaModel(num_terms=16053, num_topics=3, decay=0.5, chunksize=2000) 혼란도:  1306.206982846796 응집도:  -2.018729437153089\n",
      "2 LdaModel(num_terms=16053, num_topics=4, decay=0.5, chunksize=2000) 혼란도:  1679.0308458484785 응집도:  -2.051081246676257\n",
      "2 LdaModel(num_terms=16053, num_topics=5, decay=0.5, chunksize=2000) 혼란도:  2132.2718691564255 응집도:  -3.442287578124673\n",
      "0\n",
      "******************************\n",
      "('사진', 0.0050930204)\n",
      "('영화', 0.004813151)\n",
      "('감독', 0.0045084837)\n",
      "('방송', 0.00399219)\n",
      "('기생충', 0.0035299081)\n",
      "('트롯', 0.0034172633)\n",
      "('사람', 0.00329975)\n",
      "('아카데미', 0.0032670596)\n",
      "\n",
      "******************************\n",
      "1\n",
      "******************************\n",
      "('코로나', 0.0085522095)\n",
      "('신천지', 0.005096599)\n",
      "('환자', 0.004577194)\n",
      "('감염', 0.004281922)\n",
      "('사람', 0.0041169845)\n",
      "('마스크', 0.00410791)\n",
      "('교회', 0.0039493465)\n",
      "('진자', 0.0039019545)\n",
      "\n",
      "******************************\n",
      "2\n",
      "******************************\n",
      "('코로나', 0.0056402623)\n",
      "('사람', 0.0053940457)\n",
      "('사진', 0.0047338665)\n",
      "('방송', 0.004028376)\n",
      "('한국', 0.0039574513)\n",
      "('신천지', 0.003946771)\n",
      "('마스크', 0.0038850508)\n",
      "('생각', 0.0032449733)\n",
      "\n",
      "******************************\n",
      "세계 분야 데이터\n",
      "3 LdaModel(num_terms=16053, num_topics=3, decay=0.5, chunksize=2000) 혼란도:  712.5435298141622 응집도:  -0.18513028898308256\n",
      "3 LdaModel(num_terms=16053, num_topics=4, decay=0.5, chunksize=2000) 혼란도:  859.6323540254621 응집도:  -0.1875239308125875\n",
      "3 LdaModel(num_terms=16053, num_topics=5, decay=0.5, chunksize=2000) 혼란도:  992.5967672608526 응집도:  -0.1547183448543122\n",
      "0\n",
      "******************************\n",
      "('중국', 0.017156323)\n",
      "('코로나', 0.011382596)\n",
      "('일본', 0.010378136)\n",
      "('감염', 0.009494152)\n",
      "('신종', 0.008925028)\n",
      "('우한', 0.007249672)\n",
      "('환자', 0.006069031)\n",
      "('정부', 0.0055548036)\n",
      "\n",
      "******************************\n",
      "1\n",
      "******************************\n",
      "('코로나', 0.02469214)\n",
      "('중국', 0.011496868)\n",
      "('감염', 0.008647164)\n",
      "('신종', 0.008131515)\n",
      "('한국', 0.007975095)\n",
      "('진자', 0.0072376453)\n",
      "('일본', 0.0068659233)\n",
      "('미국', 0.0062709157)\n",
      "\n",
      "******************************\n",
      "2\n",
      "******************************\n",
      "('중국', 0.019471394)\n",
      "('코로나', 0.015002692)\n",
      "('신종', 0.008957765)\n",
      "('한국', 0.008927963)\n",
      "('우한', 0.008348638)\n",
      "('일본', 0.0070560533)\n",
      "('마스크', 0.0060297567)\n",
      "('미국', 0.0057869568)\n",
      "\n",
      "******************************\n",
      "IT/과학 분야 데이터\n",
      "4 LdaModel(num_terms=16053, num_topics=3, decay=0.5, chunksize=2000) 혼란도:  821.2924312248815 응집도:  -0.7058952594043598\n",
      "4 LdaModel(num_terms=16053, num_topics=4, decay=0.5, chunksize=2000) 혼란도:  1011.7381865048135 응집도:  -0.6509302639739944\n",
      "4 LdaModel(num_terms=16053, num_topics=5, decay=0.5, chunksize=2000) 혼란도:  1230.0548920609895 응집도:  -0.7744887430087489\n",
      "0\n",
      "******************************\n",
      "('코로나', 0.005832231)\n",
      "('중국', 0.0048591793)\n",
      "('환자', 0.0048573567)\n",
      "('갤럭시', 0.0039003573)\n",
      "('더블', 0.0038857707)\n",
      "('미국', 0.0033115672)\n",
      "('국내', 0.0032038267)\n",
      "('진자', 0.0031534128)\n",
      "\n",
      "******************************\n",
      "1\n",
      "******************************\n",
      "('갤럭시', 0.012132702)\n",
      "('코로나', 0.009885326)\n",
      "('환자', 0.0086562345)\n",
      "('서울', 0.0047012037)\n",
      "('감염', 0.0042909854)\n",
      "('바이러스', 0.004144982)\n",
      "('삼성', 0.004064308)\n",
      "('진자', 0.0038851162)\n",
      "\n",
      "******************************\n",
      "2\n",
      "******************************\n",
      "('코로나', 0.010599918)\n",
      "('중국', 0.006284618)\n",
      "('바이러스', 0.0054099704)\n",
      "('갤럭시', 0.005091318)\n",
      "('개발', 0.004587248)\n",
      "('삼성', 0.0044953884)\n",
      "('미국', 0.004208554)\n",
      "('스마트폰', 0.0039366405)\n",
      "\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "word_probs = []\n",
    "for i in range(5) :\n",
    "    best_score = 0\n",
    "    best_num_topics = 0\n",
    "    section = ['경제','사회','생활/문화','세계','IT/과학']\n",
    "    print('%s 분야 데이터'%(section[i]))\n",
    "    for num_topics in [3,4,5]:\n",
    "            globals()['models_{}'.format(num_topics)] = LdaModel(\n",
    "            corpus=globals()['corpus_{}'.format(i+1)],\n",
    "            num_topics=num_topics,\n",
    "            passes=3,\n",
    "            iterations=30,\n",
    "            id2word=id2word,\n",
    "            random_state=55)\n",
    "            log_pp = globals()['models_{}'.format(num_topics)].log_perplexity(globals()['corpus_test_{}'.format(i+1)])\n",
    "            coh = CoherenceModel(model=globals()['models_{}'.format(num_topics)], corpus=globals()['corpus_test_{}'.format(i+1)], coherence='u_mass')\n",
    "            print(i, globals()['models_{}'.format(num_topics)],\"혼란도: \",2 ** (-log_pp),\"응집도: \",coh.get_coherence())\n",
    "            if num_topics == 3 :\n",
    "                best_score = 2 **(-log_pp)\n",
    "                best_num_topics = num_topics\n",
    "            else :\n",
    "                if 2 **(-log_pp) < best_score : \n",
    "                    best_score = 2 **(-log_pp)\n",
    "                    best_num_topics = num_topics\n",
    "            \n",
    "    for words in globals()['models_{}'.format(best_num_topics)].show_topics(formatted=False,num_words=8, num_topics = best_num_topics):\n",
    "        print(words[0])\n",
    "        print(\"******************************\")\n",
    "        \n",
    "        for word_prob in words[1]:\n",
    "            print(word_prob)\n",
    "            word_probs.append((i, word_prob[0],words[0]))\n",
    "        print(\"\")\n",
    "        print(\"******************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_topics = pd.DataFrame(word_probs, columns = ['labels','topic_words','topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>topic_words</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>마스크</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>코로나</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>미국</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>중국</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>정부</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4</td>\n",
       "      <td>갤럭시</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>4</td>\n",
       "      <td>개발</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4</td>\n",
       "      <td>삼성</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>4</td>\n",
       "      <td>미국</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>4</td>\n",
       "      <td>스마트폰</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels topic_words  topic\n",
       "0         0         마스크      0\n",
       "1         0         코로나      0\n",
       "2         0          미국      0\n",
       "3         0          중국      0\n",
       "4         0          정부      0\n",
       "..      ...         ...    ...\n",
       "115       4         갤럭시      2\n",
       "116       4          개발      2\n",
       "117       4          삼성      2\n",
       "118       4          미국      2\n",
       "119       4        스마트폰      2\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_topics = pd.DataFrame(total_topics.groupby(['labels', 'topic'])['topic_words'].apply(lambda x: ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>topic_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>마스크 코로나 미국 중국 정부 억원 갤럭시 사진</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>코로나 지역 만원 정부 서울 마스크 회장 아파트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>코로나 마스크 정부 만원 한국 서울 억원 주택</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>환자 병원 코로나 확진 격리 신종 진자 감염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>코로나 병원 진자 환자 대구 검사 신천지 마스크</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>코로나 마스크 경찰 서울 지난 격리 확인 환자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>사진 영화 감독 방송 기생충 트롯 사람 아카데미</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>코로나 신천지 환자 감염 사람 마스크 교회 진자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>코로나 사람 사진 방송 한국 신천지 마스크 생각</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>중국 코로나 일본 감염 신종 우한 환자 정부</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>코로나 중국 감염 신종 한국 진자 일본 미국</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>중국 코로나 신종 한국 우한 일본 마스크 미국</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>코로나 중국 환자 갤럭시 더블 미국 국내 진자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>갤럭시 코로나 환자 서울 감염 바이러스 삼성 진자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>코로나 중국 바이러스 갤럭시 개발 삼성 미국 스마트폰</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                topic_words\n",
       "labels topic                               \n",
       "0      0         마스크 코로나 미국 중국 정부 억원 갤럭시 사진\n",
       "       1         코로나 지역 만원 정부 서울 마스크 회장 아파트\n",
       "       2          코로나 마스크 정부 만원 한국 서울 억원 주택\n",
       "1      0           환자 병원 코로나 확진 격리 신종 진자 감염\n",
       "       1         코로나 병원 진자 환자 대구 검사 신천지 마스크\n",
       "       2          코로나 마스크 경찰 서울 지난 격리 확인 환자\n",
       "2      0         사진 영화 감독 방송 기생충 트롯 사람 아카데미\n",
       "       1         코로나 신천지 환자 감염 사람 마스크 교회 진자\n",
       "       2         코로나 사람 사진 방송 한국 신천지 마스크 생각\n",
       "3      0           중국 코로나 일본 감염 신종 우한 환자 정부\n",
       "       1           코로나 중국 감염 신종 한국 진자 일본 미국\n",
       "       2          중국 코로나 신종 한국 우한 일본 마스크 미국\n",
       "4      0          코로나 중국 환자 갤럭시 더블 미국 국내 진자\n",
       "       1        갤럭시 코로나 환자 서울 감염 바이러스 삼성 진자\n",
       "       2      코로나 중국 바이러스 갤럭시 개발 삼성 미국 스마트폰"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원 데이터에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_1 = []\n",
    "for i in range(len(corpus_1)) :\n",
    "    doc_topic_dist = models_3.get_document_topics(corpus_1[i], minimum_probability=0)\n",
    "    sorted_doc_topic = sorted(doc_topic_dist, key=lambda x: x[1],reverse=True)\n",
    "    topic_1.append(sorted_doc_topic[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhgus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(new_df)) :\n",
    "    new_df.topics[i] = list(set(new_df.loc[i,'topics']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_20200501 = new_df.query('date == 20200501')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = cv.fit_transform(new_df.loc[0,'topics'])\n",
    "data_1 = Sparse2Corpus(data_1.T)\n",
    "id2word_1 = dict(enumerate(cv.get_feature_names()))\n",
    "data_2 = cv.fit_transform(new_df.loc[1, 'topics'])\n",
    "data_2 = Sparse2Corpus(data_2.T)\n",
    "id2word_2 = dict(enumerate(cv.get_feature_names()))\n",
    "data_3 = cv.fit_transform(new_df.loc[2, 'topics'])\n",
    "data_3 = Sparse2Corpus(data_3.T)\n",
    "id2word_3 = dict(enumerate(cv.get_feature_names()))\n",
    "data_4 = cv.fit_transform(new_df.loc[3, 'topics'])\n",
    "data_4 = Sparse2Corpus(data_4.T)\n",
    "id2word_4 = dict(enumerate(cv.get_feature_names()))\n",
    "data_5 = cv.fit_transform(new_df.loc[4, 'topics'])\n",
    "data_5 = Sparse2Corpus(data_5.T)\n",
    "id2word_5 = dict(enumerate(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "******************************\n",
      "('기흥구', 0.06474707)\n",
      "('자동화', 0.06462696)\n",
      "('분위기', 0.064415604)\n",
      "('완료', 0.064385146)\n",
      "('전락', 0.06412507)\n",
      "('앵커', 0.064010896)\n",
      "('공정', 0.06377643)\n",
      "('용인', 0.063270204)\n",
      "\n",
      "******************************\n",
      "1\n",
      "******************************\n",
      "('동백', 0.062179916)\n",
      "('참여자', 0.061993722)\n",
      "('그룹', 0.06189674)\n",
      "('장비', 0.061646957)\n",
      "('구의', 0.06148547)\n",
      "('명의', 0.06137533)\n",
      "('강남구', 0.061075278)\n",
      "('재배', 0.060395874)\n",
      "\n",
      "******************************\n",
      "2\n",
      "******************************\n",
      "('직장', 0.06842242)\n",
      "('직항', 0.06829517)\n",
      "('라인', 0.068021715)\n",
      "('송출', 0.06801295)\n",
      "('생산', 0.067388214)\n",
      "('동향', 0.06609701)\n",
      "('기업', 0.065372095)\n",
      "('상승', 0.06477467)\n",
      "\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "models_1_topic = []\n",
    "models_1 = LdaModel(corpus=data_1 ,\n",
    "            num_topics=3,\n",
    "            passes=3,\n",
    "            iterations=20,\n",
    "            id2word=id2word_1,\n",
    "            random_state=55)\n",
    "for words in models_1.show_topics(formatted=False,num_words=8, num_topics = best_num_topics):\n",
    "        print(words[0])\n",
    "        print(\"******************************\")\n",
    "        \n",
    "        for word_prob in words[1]:\n",
    "            print(word_prob)\n",
    "            models_1_topic.append((word_prob[0]))\n",
    "        print(\"\")\n",
    "        print(\"******************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "******************************\n",
      "('대통령', 0.06221969)\n",
      "('이주', 0.06209241)\n",
      "('반응', 0.061901387)\n",
      "('육군', 0.061843697)\n",
      "('재판', 0.061584383)\n",
      "('국민', 0.06158137)\n",
      "('야권', 0.06130844)\n",
      "('폐렴', 0.060499698)\n",
      "\n",
      "******************************\n",
      "1\n",
      "******************************\n",
      "('만큼', 0.06724103)\n",
      "('형식', 0.067038946)\n",
      "('당국', 0.066930875)\n",
      "('인플루엔자', 0.06666866)\n",
      "('뉴시스', 0.06649471)\n",
      "('물의', 0.06636546)\n",
      "('검역', 0.066114396)\n",
      "('국가', 0.06471682)\n",
      "\n",
      "******************************\n",
      "2\n",
      "******************************\n",
      "('최종', 0.065775335)\n",
      "('취지', 0.06565194)\n",
      "('먹방', 0.06539302)\n",
      "('사생활', 0.06538473)\n",
      "('변희', 0.06466737)\n",
      "('대상', 0.06265633)\n",
      "('말살', 0.06231496)\n",
      "('이성윤', 0.062173665)\n",
      "\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "models_2_topic = []\n",
    "models_2 = LdaModel(corpus=data_2 ,\n",
    "            num_topics=3,\n",
    "            passes=3,\n",
    "            iterations=20,\n",
    "            id2word=id2word_2,\n",
    "            random_state=55)\n",
    "for words in models_2.show_topics(formatted=False,num_words=8, num_topics = best_num_topics):\n",
    "        print(words[0])\n",
    "        print(\"******************************\")\n",
    "        \n",
    "        for word_prob in words[1]:\n",
    "            print(word_prob)\n",
    "            models_2_topic.append((word_prob[0]))\n",
    "        print(\"\")\n",
    "        print(\"******************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "******************************\n",
      "('명장', 0.06247868)\n",
      "('착오', 0.06236683)\n",
      "('빙자', 0.062146757)\n",
      "('일이', 0.06213464)\n",
      "('대상', 0.0618188)\n",
      "('칭찬', 0.06145959)\n",
      "('직후', 0.061038665)\n",
      "('호감', 0.060991023)\n",
      "\n",
      "******************************\n",
      "1\n",
      "******************************\n",
      "('모델', 0.06720255)\n",
      "('훤히', 0.06700263)\n",
      "('마크', 0.066895165)\n",
      "('최고경영자', 0.066629715)\n",
      "('더욱', 0.06646058)\n",
      "('분위기', 0.06634183)\n",
      "('간음', 0.065933116)\n",
      "('출고', 0.06544443)\n",
      "\n",
      "******************************\n",
      "2\n",
      "******************************\n",
      "('해당', 0.06552673)\n",
      "('현대차', 0.06540151)\n",
      "('반응', 0.06514384)\n",
      "('영역', 0.06513017)\n",
      "('세상', 0.064488076)\n",
      "('성행위', 0.06336708)\n",
      "('먼지', 0.06316415)\n",
      "('목표', 0.06262831)\n",
      "\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "models_3_topic = []\n",
    "models_3 = LdaModel(corpus=data_3 ,\n",
    "            num_topics=3,\n",
    "            passes=3,\n",
    "            iterations=20,\n",
    "            id2word=id2word_3,\n",
    "            random_state=55)\n",
    "for words in models_3.show_topics(formatted=False,num_words=8, num_topics = best_num_topics):\n",
    "        print(words[0])\n",
    "        print(\"******************************\")\n",
    "        \n",
    "        for word_prob in words[1]:\n",
    "            print(word_prob)\n",
    "            models_3_topic.append((word_prob[0]))\n",
    "        print(\"\")\n",
    "        print(\"******************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "******************************\n",
      "('변명', 0.06497209)\n",
      "('장애', 0.064900964)\n",
      "('소비자', 0.064689174)\n",
      "('일이', 0.06465802)\n",
      "('차이', 0.064322084)\n",
      "('대화', 0.06416064)\n",
      "('자고', 0.0638097)\n",
      "('호감', 0.0634499)\n",
      "\n",
      "******************************\n",
      "1\n",
      "******************************\n",
      "('분쟁', 0.064619645)\n",
      "('호흡기', 0.0644274)\n",
      "('박쥐', 0.06432338)\n",
      "('중화권', 0.0640685)\n",
      "('라며', 0.063907206)\n",
      "('생활', 0.06375685)\n",
      "('가정', 0.06342319)\n",
      "('진원', 0.06311528)\n",
      "\n",
      "******************************\n",
      "2\n",
      "******************************\n",
      "('폐렴', 0.065418676)\n",
      "('포토', 0.0652973)\n",
      "('생산', 0.065033)\n",
      "('엔터테인먼트', 0.0650276)\n",
      "('안과', 0.06446827)\n",
      "('아사코', 0.06322768)\n",
      "('비용', 0.0632272)\n",
      "('자녀', 0.06258089)\n",
      "\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "models_4_topic = []\n",
    "models_4 = LdaModel(corpus=data_4 ,\n",
    "            num_topics=3,\n",
    "            passes=3,\n",
    "            iterations=20,\n",
    "            id2word=id2word_4,\n",
    "            random_state=55)\n",
    "for words in models_4.show_topics(formatted=False,num_words=8, num_topics = best_num_topics):\n",
    "        print(words[0])\n",
    "        print(\"******************************\")\n",
    "        \n",
    "        for word_prob in words[1]:\n",
    "            print(word_prob)\n",
    "            models_4_topic.append((word_prob[0]))\n",
    "        print(\"\")\n",
    "        print(\"******************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "******************************\n",
      "('문구', 0.06206917)\n",
      "('액티브', 0.061949216)\n",
      "('소프트', 0.061745267)\n",
      "('분위기', 0.06174486)\n",
      "('기술', 0.06140807)\n",
      "('임시', 0.061402503)\n",
      "('셰프', 0.0612203)\n",
      "('소음', 0.060744364)\n",
      "\n",
      "******************************\n",
      "1\n",
      "******************************\n",
      "('방법', 0.06789181)\n",
      "('측정', 0.06769062)\n",
      "('무인항공기', 0.067579634)\n",
      "('역할', 0.06731709)\n",
      "('목표', 0.06714136)\n",
      "('베트남', 0.06695251)\n",
      "('공개', 0.06592323)\n",
      "('그렘린', 0.06524342)\n",
      "\n",
      "******************************\n",
      "2\n",
      "******************************\n",
      "('차이', 0.06533069)\n",
      "('창업', 0.06520396)\n",
      "('방패', 0.064945124)\n",
      "('샤오미', 0.06493873)\n",
      "('색상', 0.06439398)\n",
      "('무장', 0.06344917)\n",
      "('블루', 0.06294123)\n",
      "('애플', 0.06222344)\n",
      "\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "models_5_topic = []\n",
    "models_5 = LdaModel(corpus=data_5 ,\n",
    "            num_topics=3,\n",
    "            passes=3,\n",
    "            iterations=20,\n",
    "            id2word=id2word_5,\n",
    "            random_state=55)\n",
    "for words in models_5.show_topics(formatted=False,num_words=8):\n",
    "        print(words[0])\n",
    "        print(\"******************************\")\n",
    "        \n",
    "        for word_prob in words[1]:\n",
    "            print(word_prob)\n",
    "            models_5_topic.append((word_prob[0]))\n",
    "        print(\"\")\n",
    "        print(\"******************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_topics = [models_1_topic, models_2_topic, models_3_topic, models_4_topic, models_5_topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['기흥구',\n",
       "  '자동화',\n",
       "  '분위기',\n",
       "  '완료',\n",
       "  '전락',\n",
       "  '앵커',\n",
       "  '공정',\n",
       "  '용인',\n",
       "  '동백',\n",
       "  '참여자',\n",
       "  '그룹',\n",
       "  '장비',\n",
       "  '구의',\n",
       "  '명의',\n",
       "  '강남구',\n",
       "  '재배',\n",
       "  '직장',\n",
       "  '직항',\n",
       "  '라인',\n",
       "  '송출',\n",
       "  '생산',\n",
       "  '동향',\n",
       "  '기업',\n",
       "  '상승'],\n",
       " ['대통령',\n",
       "  '이주',\n",
       "  '반응',\n",
       "  '육군',\n",
       "  '재판',\n",
       "  '국민',\n",
       "  '야권',\n",
       "  '폐렴',\n",
       "  '만큼',\n",
       "  '형식',\n",
       "  '당국',\n",
       "  '인플루엔자',\n",
       "  '뉴시스',\n",
       "  '물의',\n",
       "  '검역',\n",
       "  '국가',\n",
       "  '최종',\n",
       "  '취지',\n",
       "  '먹방',\n",
       "  '사생활',\n",
       "  '변희',\n",
       "  '대상',\n",
       "  '말살',\n",
       "  '이성윤'],\n",
       " ['명장',\n",
       "  '착오',\n",
       "  '빙자',\n",
       "  '일이',\n",
       "  '대상',\n",
       "  '칭찬',\n",
       "  '직후',\n",
       "  '호감',\n",
       "  '모델',\n",
       "  '훤히',\n",
       "  '마크',\n",
       "  '최고경영자',\n",
       "  '더욱',\n",
       "  '분위기',\n",
       "  '간음',\n",
       "  '출고',\n",
       "  '해당',\n",
       "  '현대차',\n",
       "  '반응',\n",
       "  '영역',\n",
       "  '세상',\n",
       "  '성행위',\n",
       "  '먼지',\n",
       "  '목표'],\n",
       " ['변명',\n",
       "  '장애',\n",
       "  '소비자',\n",
       "  '일이',\n",
       "  '차이',\n",
       "  '대화',\n",
       "  '자고',\n",
       "  '호감',\n",
       "  '분쟁',\n",
       "  '호흡기',\n",
       "  '박쥐',\n",
       "  '중화권',\n",
       "  '라며',\n",
       "  '생활',\n",
       "  '가정',\n",
       "  '진원',\n",
       "  '폐렴',\n",
       "  '포토',\n",
       "  '생산',\n",
       "  '엔터테인먼트',\n",
       "  '안과',\n",
       "  '아사코',\n",
       "  '비용',\n",
       "  '자녀'],\n",
       " ['문구',\n",
       "  '액티브',\n",
       "  '소프트',\n",
       "  '분위기',\n",
       "  '기술',\n",
       "  '임시',\n",
       "  '셰프',\n",
       "  '소음',\n",
       "  '방법',\n",
       "  '측정',\n",
       "  '무인항공기',\n",
       "  '역할',\n",
       "  '목표',\n",
       "  '베트남',\n",
       "  '공개',\n",
       "  '그렘린',\n",
       "  '차이',\n",
       "  '창업',\n",
       "  '방패',\n",
       "  '샤오미',\n",
       "  '색상',\n",
       "  '무장',\n",
       "  '블루',\n",
       "  '애플']]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = pd.DataFrame(today_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = today.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "today.columns = ['경제','사회','생활/문화','세계','IT/과학']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "today.to_csv('today_topics.csv', index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
